#+TITLE: Guile Reasoning Model Setup
#+AUTHOR: dsp-dr
#+PROPERTY: header-args :mkdirp yes

* Project Setup

This file creates the initial structure for implementing reasoning models in Guile Scheme,
based on "Build a Reasoning Model (From Scratch)" by Sebastian Raschka.

** Directory Structure

#+begin_src shell :tangle no
mkdir -p src/{tokenizer,model,generation,inference,training,evaluation}
mkdir -p examples tests docs benchmarks data
#+end_src

** README

#+begin_src org :tangle README.org
#+TITLE: Guile Reasoning Model
#+AUTHOR: dsp-dr

* Overview

Implementation of reasoning models in Guile Scheme, based on Sebastian Raschka's 
"Build a Reasoning Model (From Scratch)".

* Project Structure

- =src/= - Core implementation
  - =tokenizer/= - BPE tokenization (Chapter 2)
  - =model/= - Model architecture and loading
  - =generation/= - Text generation with KV caching
  - =inference/= - Inference scaling techniques (Chapter 4)
  - =training/= - RL and distillation methods (Chapters 5-6)
  - =evaluation/= - Evaluation metrics (Chapter 3)
- =examples/= - Usage examples
- =tests/= - Test suite
- =docs/= - Additional documentation

* Dependencies

- Guile 3.0+
- guile-json (for tokenizer files)
- guile-pfds (persistent data structures)

* Quick Start

#+begin_src shell
make setup
make test
guile examples/basic-generation.scm
#+end_src
#+end_src

** Makefile

#+begin_src makefile :tangle Makefile
GUILE = guile
GUILD = guild
GUILE_WARNINGS = -Wunbound-variable -Warity-mismatch -Wformat

SOURCES = $(shell find src -name "*.scm")
COMPILED = $(SOURCES:%.scm=%.go)

.PHONY: all compile test clean setup

all: compile

setup:
	@echo "Setting up project structure..."
	@mkdir -p src/{tokenizer,model,generation,inference,training,evaluation}
	@mkdir -p examples tests docs benchmarks data
	@echo "Setup complete!"

compile: $(COMPILED)

%.go: %.scm
	$(GUILD) compile $(GUILE_WARNINGS) -o $@ $

test:
	$(GUILE) run-tests.scm

clean:
	find . -name "*.go" -delete
	find . -name "*~" -delete

run-example:
	$(GUILE) -L src examples/basic-generation.scm
#+end_src

** Core Module Structure

*** Tokenizer Base

#+begin_src scheme :tangle src/tokenizer/base.scm
;;; tokenizer/base.scm - Basic tokenizer interface
(define-module (tokenizer base)
  #:use-module (ice-9 match)
  #:use-module (srfi srfi-1)
  #:use-module (srfi srfi-9)
  #:export (<tokenizer>
            make-tokenizer
            tokenizer?
            encode
            decode
            tokenizer-vocab-size
            tokenizer-eos-token-id))

(define-record-type <tokenizer>
  (make-tokenizer vocab encode-proc decode-proc special-tokens)
  tokenizer?
  (vocab tokenizer-vocab)
  (encode-proc tokenizer-encode-proc)
  (decode-proc tokenizer-decode-proc)
  (special-tokens tokenizer-special-tokens))

(define (encode tokenizer text)
  "Encode text to token IDs"
  ((tokenizer-encode-proc tokenizer) text))

(define (decode tokenizer token-ids)
  "Decode token IDs to text"
  ((tokenizer-decode-proc tokenizer) token-ids))

(define (tokenizer-vocab-size tokenizer)
  "Get vocabulary size"
  (hash-count (const #t) (tokenizer-vocab tokenizer)))

(define (tokenizer-eos-token-id tokenizer)
  "Get end-of-sequence token ID"
  (hash-ref (tokenizer-special-tokens tokenizer) 'eos))
#+end_src

*** Model Base

#+begin_src scheme :tangle src/model/base.scm
;;; model/base.scm - Base model interface
(define-module (model base)
  #:use-module (srfi srfi-9)
  #:use-module (srfi srfi-43)  ; vectors
  #:export (<model>
            make-model
            model?
            model-forward
            model-config
            model-eval-mode!))

(define-record-type <model>
  (make-model config forward-proc parameters)
  model?
  (config model-config)
  (forward-proc model-forward-proc)
  (parameters model-parameters))

(define (model-forward model input-ids #:key (cache #f))
  "Forward pass through model"
  ((model-forward-proc model) input-ids cache))

(define (model-eval-mode! model)
  "Set model to evaluation mode"
  ;; In a real implementation, this would disable dropout, etc.
  #t)
#+end_src

*** Text Generation

#+begin_src scheme :tangle src/generation/basic.scm
;;; generation/basic.scm - Basic text generation
(define-module (generation basic)
  #:use-module (tokenizer base)
  #:use-module (model base)
  #:use-module (srfi srfi-1)
  #:use-module (srfi srfi-43)
  #:export (generate-text-basic
            generate-text-with-cache))

(define (argmax vec)
  "Return index of maximum value in vector"
  (let ((max-val (vector-ref vec 0))
        (max-idx 0))
    (do ((i 1 (+ i 1)))
        ((>= i (vector-length vec)) max-idx)
      (when (> (vector-ref vec i) max-val)
        (set! max-val (vector-ref vec i))
        (set! max-idx i)))))

(define* (generate-text-basic model tokenizer prompt 
                              #:key (max-new-tokens 100) (eos-token-id #f))
  "Basic sequential text generation"
  (let* ((input-ids (encode tokenizer prompt))
         (generated '()))
    
    (model-eval-mode! model)
    
    (do ((i 0 (+ i 1))
         (current-ids input-ids))
        ((or (>= i max-new-tokens)
             (and eos-token-id 
                  (not (null? generated))
                  (= (car generated) eos-token-id)))
         (decode tokenizer (reverse generated)))
      
      (let* ((logits (model-forward model current-ids))
             (last-logits (vector-ref logits (- (vector-length logits) 1)))
             (next-token (argmax last-logits)))
        (set! generated (cons next-token generated))
        (set! current-ids (append current-ids (list next-token)))))))
#+end_src

*** KV Cache Implementation

#+begin_src scheme :tangle src/generation/kv-cache.scm
;;; generation/kv-cache.scm - Key-Value cache for faster generation
(define-module (generation kv-cache)
  #:use-module (srfi srfi-9)
  #:use-module (srfi srfi-43)
  #:export (<kv-cache>
            make-kv-cache
            kv-cache-get
            kv-cache-update!
            kv-cache-reset!))

(define-record-type <kv-cache>
  (make-kv-cache-internal layers cache-data)
  kv-cache?
  (layers kv-cache-layers)
  (cache-data kv-cache-data))

(define (make-kv-cache n-layers)
  "Create a new KV cache for n-layers"
  (make-kv-cache-internal n-layers (make-vector n-layers #f)))

(define (kv-cache-get cache layer-idx)
  "Get cached values for layer"
  (vector-ref (kv-cache-data cache) layer-idx))

(define (kv-cache-update! cache layer-idx value)
  "Update cache for layer"
  (vector-set! (kv-cache-data cache) layer-idx value))

(define (kv-cache-reset! cache)
  "Reset all cache entries"
  (vector-fill! (kv-cache-data cache) #f))
#+end_src

** Example Files

*** Basic Generation Example

#+begin_src scheme :tangle examples/basic-generation.scm
#!/usr/bin/env guile
!#
;;; basic-generation.scm - Basic text generation example

(add-to-load-path "../src")

(use-modules (tokenizer base)
             (model base)
             (generation basic)
             (ice-9 format))

(define (create-dummy-tokenizer)
  "Create a dummy tokenizer for demonstration"
  (let ((vocab (make-hash-table))
        (reverse-vocab (make-hash-table)))
    ;; Simple word-level tokenization
    (for-each (lambda (pair)
                (hash-set! vocab (car pair) (cdr pair))
                (hash-set! reverse-vocab (cdr pair) (car pair)))
              '(("Hello" . 1) ("world" . 2) ("!" . 3) 
                ("<eos>" . 4) (" " . 5)))
    
    (make-tokenizer 
     vocab
     (lambda (text)
       ;; Very simple tokenization
       (map (lambda (word) 
              (hash-ref vocab word 0))
            (string-split text #\space)))
     (lambda (ids)
       (string-join 
        (map (lambda (id) 
               (hash-ref reverse-vocab id "<??>"))
             ids)
        " "))
     (alist->hash-table '((eos . 4))))))

(define (create-dummy-model)
  "Create a dummy model that returns random logits"
  (make-model
   '((vocab-size . 100)
     (n-layers . 2))
   (lambda (input-ids cache)
     ;; Return random logits
     (let ((seq-len (length input-ids)))
       (vector-unfold (lambda (i)
                       (vector-unfold (lambda (j) 
                                       (random:uniform))
                                     100))
                     seq-len)))
   #f))

(define (main)
  (let ((tokenizer (create-dummy-tokenizer))
        (model (create-dummy-model)))
    
    (format #t "Basic text generation example~%")
    (format #t "=============================~%")
    
    (let ((prompt "Hello world"))
      (format #t "Prompt: ~a~%" prompt)
      (format #t "Generated: ~a~%" 
              (generate-text-basic model tokenizer prompt 
                                  #:max-new-tokens 10
                                  #:eos-token-id 4)))))

(when (batch-mode?)
  (main))
#+end_src

*** Chain-of-Thought Example

#+begin_src scheme :tangle examples/cot-reasoning.scm
#!/usr/bin/env guile
!#
;;; cot-reasoning.scm - Chain-of-thought reasoning example

(add-to-load-path "../src")

(use-modules (ice-9 format)
             (ice-9 match))

(define (demonstrate-cot-prompt)
  "Show how to structure prompts for chain-of-thought reasoning"
  (let ((problem "If a train travels 60 miles in 1 hour, how far will it travel in 2.5 hours?"))
    
    (format #t "Chain-of-Thought Reasoning Example~%")
    (format #t "==================================~%~%")
    
    (format #t "Problem: ~a~%~%" problem)
    
    (format #t "Standard prompt:~%")
    (format #t "Q: ~a~%" problem)
    (format #t "A: [Model would give direct answer]~%~%")
    
    (format #t "Chain-of-thought prompt:~%")
    (format #t "Q: ~a Let's think step by step.~%" problem)
    (format #t "A: Step 1: The train travels 60 miles in 1 hour~%")
    (format #t "   Step 2: We need to find distance for 2.5 hours~%")
    (format #t "   Step 3: Distance = Speed × Time~%")
    (format #t "   Step 4: Distance = 60 miles/hour × 2.5 hours~%")
    (format #t "   Step 5: Distance = 150 miles~%")
    (format #t "   Therefore, the train will travel 150 miles.~%")))

(when (batch-mode?)
  (demonstrate-cot-prompt))
#+end_src

*** Performance Benchmarking

#+begin_src scheme :tangle examples/performance-demo.scm
#!/usr/bin/env guile
!#
;;; performance-demo.scm - Demonstrate performance improvements

(add-to-load-path "../src")

(use-modules (ice-9 format)
             (ice-9 time))

(define (measure-generation-time generate-fn name iterations)
  "Measure time for text generation"
  (format #t "~%Measuring ~a (~a iterations)...~%" name iterations)
  (let ((start (get-internal-real-time)))
    (do ((i 0 (+ i 1)))
        ((>= i iterations))
      (generate-fn))
    (let* ((end (get-internal-real-time))
           (elapsed (/ (- end start) internal-time-units-per-second))
           (tokens-per-sec (/ (* iterations 50) elapsed))) ; assume 50 tokens
      (format #t "Time: ~,2f seconds~%" elapsed)
      (format #t "Speed: ~,0f tokens/second~%" tokens-per-sec))))

(define (dummy-generate-basic)
  "Simulate basic generation"
  (usleep 10000)) ; 10ms per token

(define (dummy-generate-cached)
  "Simulate cached generation"
  (usleep 2000))  ; 2ms per token

(define (main)
  (format #t "Performance Comparison Demo~%")
  (format #t "==========================~%")
  
  (measure-generation-time dummy-generate-basic "Basic generation" 10)
  (measure-generation-time dummy-generate-cached "Cached generation" 10)
  
  (format #t "~%Note: Real implementation would show ~5-6x speedup with KV caching~%"))

(when (batch-mode?)
  (main))
#+end_src

** Test Framework

#+begin_src scheme :tangle run-tests.scm
#!/usr/bin/env guile
!#
;;; run-tests.scm - Test runner

(add-to-load-path "src")
(use-modules (srfi srfi-64))

(test-runner-factory
 (lambda ()
   (let ((runner (test-runner-simple)))
     (test-runner-on-final! runner
       (lambda (runner)
         (format #t "~%Test Summary:~%")
         (format #t "Passed: ~a~%" (test-runner-pass-count runner))
         (format #t "Failed: ~a~%" (test-runner-fail-count runner))
         (format #t "Skipped: ~a~%~%" (test-runner-skip-count runner))))
     runner)))

;; Run all test files
(for-each (lambda (test-file)
            (format #t "Running ~a...~%" test-file)
            (load test-file))
          (find-files "tests" ".*\\.scm$"))
#+end_src

** Initial Test

#+begin_src scheme :tangle tests/tokenizer-test.scm
;;; tokenizer-test.scm - Tokenizer tests

(use-modules (srfi srfi-64)
             (tokenizer base))

(test-begin "tokenizer-base")

(test-assert "Create tokenizer"
  (tokenizer? (make-tokenizer 
               (make-hash-table)
               (lambda (x) '())
               (lambda (x) "")
               (make-hash-table))))

(test-end "tokenizer-base")
#+end_src

** Documentation

#+begin_src org :tangle docs/implementation-notes.org
#+TITLE: Implementation Notes
#+AUTHOR: dsp-dr

* Design Decisions

** Why Guile?

- Exploring functional implementation of neural network concepts
- Leveraging Guile's macro system for DSL creation
- Integration with existing Guile ecosystem projects

** Architecture Mapping

| Book (Python/PyTorch) | Guile Implementation |
|-----------------------|---------------------|
| torch.Tensor          | SRFI-43 vectors     |
| nn.Module             | Record types        |
| Autograd              | Manual gradients    |
| CUDA/GPU              | CPU only (for now)  |

** Challenges

1. No native tensor operations - using vectors
2. No automatic differentiation - manual backprop
3. Performance limitations - focus on algorithms

** Future Directions

- FFI bindings to NumPy/PyTorch
- Pure Scheme neural network framework
- Focus on symbolic reasoning aspects
#+end_src
